{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Datasets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tamajit1998/MNIST-Dataset-using-keras/blob/master/MNIST_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avI0OkWjMv8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers.core import Dense,Dropout,Activation\n",
        "from keras import Sequential\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzSSrLI6N2RC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9xyLMPqO8cj",
        "colab_type": "code",
        "outputId": "2c2ff2c2-31db-4c63-8909-ba0bb54d8953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7d4jZTiPG_F",
        "colab_type": "code",
        "outputId": "b6784908-0874-4090-d5f7-bd5e515f29bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        }
      },
      "source": [
        "print(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N1VUXVPTbtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_classes = 10 #Digits from 0 to 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWxMG6y9UaZL",
        "colab_type": "code",
        "outputId": "06d624f8-e793-49de-cd94-dbfe165525a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x_train =  x_train.reshape(60000,784)\n",
        "x_test  =  x_test.reshape(10000,784)\n",
        "x_train =  x_train.astype('float32')\n",
        "x_test  =  x_test.astype('float32')\n",
        "x_train /=255\n",
        "x_test/=255\n",
        "print(x_train.shape[0],'train samples')\n",
        "print(x_test.shape[0],'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLFZmD65VKLK",
        "colab_type": "code",
        "outputId": "268f3dd9-2373-48dd-de49-e250ae2bc123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_train = np_utils.to_categorical(y_train,nb_classes)   \n",
        "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "Y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC__APaAXwB3",
        "colab_type": "code",
        "outputId": "a9608190-007e-406f-94b7-f79fa7da99f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(512,input_shape=(784,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0703 15:28:15.199109 139673559558016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0703 15:28:15.237575 139673559558016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0703 15:28:15.243952 139673559558016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEm45RDLbc1S",
        "colab_type": "code",
        "outputId": "29b67dc0-e84b-4456-9946-c43015755ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2cJwiiaghI2",
        "colab_type": "code",
        "outputId": "14c188bc-c84c-4c44-dd89-fcb6b346ed3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0].reshape(28,28),cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f07feb5e630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38olbrJdjIXy",
        "colab_type": "code",
        "outputId": "166584ea-60db-4ca7-eab1-f84c10743429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from keras.optimizers import SGD,Adam,RMSprop,Adamax\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adamax(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0703 15:28:30.269428 139673559558016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0703 15:28:30.281898 139673559558016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-calO8xj9tb",
        "colab_type": "code",
        "outputId": "f19ce231-5a3c-4d48-f7af-3d3348d3939c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size=128\n",
        "nb_epoch=300\n",
        "\n",
        "history=model.fit(x_train,Y_train,batch_size=batch_size,nb_epoch=nb_epoch,verbose=1,validation_data=(x_test,y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/300\n",
            " 5760/60000 [=>............................] - ETA: 1s - loss: 1.4187e-07 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9838\n",
            "Epoch 2/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9839\n",
            "Epoch 3/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9838\n",
            "Epoch 4/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9839\n",
            "Epoch 5/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9838\n",
            "Epoch 6/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9838\n",
            "Epoch 7/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.1194 - val_acc: 0.9837\n",
            "Epoch 8/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9839\n",
            "Epoch 9/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.1207 - val_acc: 0.9838\n",
            "Epoch 10/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.1205 - val_acc: 0.9840\n",
            "Epoch 11/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9837\n",
            "Epoch 12/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1217 - val_acc: 0.9838\n",
            "Epoch 13/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1218 - val_acc: 0.9837\n",
            "Epoch 14/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1219 - val_acc: 0.9839\n",
            "Epoch 15/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 0.9839\n",
            "Epoch 16/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1221 - val_acc: 0.9839\n",
            "Epoch 17/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1222 - val_acc: 0.9837\n",
            "Epoch 18/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9839\n",
            "Epoch 19/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9839\n",
            "Epoch 20/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9837\n",
            "Epoch 21/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9840\n",
            "Epoch 22/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 0.9839\n",
            "Epoch 23/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1222 - val_acc: 0.9839\n",
            "Epoch 24/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9838\n",
            "Epoch 25/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9838\n",
            "Epoch 26/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1226 - val_acc: 0.9840\n",
            "Epoch 27/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 28/300\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9840\n",
            "Epoch 29/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9841\n",
            "Epoch 30/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9841\n",
            "Epoch 31/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9840\n",
            "Epoch 32/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9838\n",
            "Epoch 33/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9839\n",
            "Epoch 34/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1226 - val_acc: 0.9840\n",
            "Epoch 35/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1226 - val_acc: 0.9840\n",
            "Epoch 36/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 37/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9839\n",
            "Epoch 38/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9839\n",
            "Epoch 39/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9839\n",
            "Epoch 40/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9839\n",
            "Epoch 41/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9839\n",
            "Epoch 42/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9840\n",
            "Epoch 43/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9840\n",
            "Epoch 44/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 45/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9839\n",
            "Epoch 46/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 47/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 48/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 49/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 50/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 51/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 52/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 53/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 54/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 55/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 56/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 57/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 58/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 59/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 60/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 61/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 62/300\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 63/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 64/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 65/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 66/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 67/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 68/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 69/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 70/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 71/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 72/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 73/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 74/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 75/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 76/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 77/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 78/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 79/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 80/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 81/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 82/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 83/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 84/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 85/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 86/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 87/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 88/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 89/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 90/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 91/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 92/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 93/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 94/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 95/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 96/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 97/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 98/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 99/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 100/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 101/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 102/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 103/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 104/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 105/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 106/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 107/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 108/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 109/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 110/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 111/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 112/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 113/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 114/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 115/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 116/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 117/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 118/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 119/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 120/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 121/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 122/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 123/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 124/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 125/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 126/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 127/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 128/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 129/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 130/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 131/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 132/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 133/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 134/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 135/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 136/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 137/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 138/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 139/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 140/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 141/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 142/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 143/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 144/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 145/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 146/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 147/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 148/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 149/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 150/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 151/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 152/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 153/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 154/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 155/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 156/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 157/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 158/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 159/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 160/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 161/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 162/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 163/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 164/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 165/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 166/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 167/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 168/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 169/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 170/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 171/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 172/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 173/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 174/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 175/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 176/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 177/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 178/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 179/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 180/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 181/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 182/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 183/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 184/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 185/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 186/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 187/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 188/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 189/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 190/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 191/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 192/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 193/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 194/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 195/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 196/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 197/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 198/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 199/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 200/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 201/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 202/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 203/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 204/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 205/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 206/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 207/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 208/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 209/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 210/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 211/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 212/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 213/300\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 214/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 215/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 216/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 217/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 218/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 219/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 220/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 221/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 222/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 223/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 224/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 225/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 226/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 227/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 228/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 229/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 230/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 231/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 232/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 233/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 234/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 235/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 236/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 237/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 238/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 239/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 240/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 241/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 242/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 243/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 244/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 245/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 246/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 247/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 248/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 249/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 250/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 251/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 252/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 253/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 254/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 255/300\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 256/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 257/300\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 258/300\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 259/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 260/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 261/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 262/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 263/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 264/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 265/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 266/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 267/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 268/300\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 269/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 270/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 271/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 272/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 273/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 274/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 275/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 276/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 277/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 278/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 279/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 280/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 281/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 282/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 283/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 284/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 285/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 286/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 287/300\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 288/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 289/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 290/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 291/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 292/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 293/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 294/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 295/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 296/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 297/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 298/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 299/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n",
            "Epoch 300/300\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcX5Dl4pkqBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model,to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOp01N45z2Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OEjNjZMpZRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}